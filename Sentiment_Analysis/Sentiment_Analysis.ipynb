{"cells":[{"metadata":{"ExecuteTime":{"end_time":"2019-06-13T21:40:06.261883Z","start_time":"2019-06-13T21:40:04.414717Z"},"trusted":true},"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nfrom torch import nn\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader, Dataset\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split\nfrom torch.functional import F\nimport spacy\nimport string\nimport re\nimport numpy as np\nfrom spacy.symbols import ORTH\nfrom collections import Counter\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\nimport keras\n","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-13T22:06:46.383049Z","start_time":"2019-06-13T22:06:46.364709Z"},"trusted":true},"cell_type":"code","source":"batch_size = 100\nembedding_size=50\nhidden_dim=100\nepochs=30\nlearning_rate=0.001","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-13T22:06:47.173622Z","start_time":"2019-06-13T22:06:47.161272Z"},"trusted":true},"cell_type":"code","source":"PATH = Path('../input/quora-question-pairs/quora-question-pairs/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(PATH.iterdir())","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-13T22:06:47.610456Z","start_time":"2019-06-13T22:06:47.600860Z"},"trusted":true},"cell_type":"code","source":"train_path = PATH/'train.csv'\nval_path = PATH/'test.csv'\n","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-14T00:37:49.197687Z","start_time":"2019-06-14T00:37:41.846183Z"},"trusted":true},"cell_type":"code","source":"train = pd.read_csv(str(train_path))\ntest = pd.read_csv(str(val_path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.sample(15000)\ntest=test.sample(5000)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-14T00:38:30.919050Z","start_time":"2019-06-14T00:38:30.110946Z"},"trusted":true},"cell_type":"code","source":"train.fillna('',inplace=True)\ntest.fillna('',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tokens!"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-14T00:38:32.144463Z","start_time":"2019-06-14T00:38:31.215602Z"},"trusted":true},"cell_type":"code","source":"re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\ndef sub_br(x):return re_br.sub(\"\\n\", x)\nmy_tok = spacy.load('en')\ndef spacy_tok(x): \n    try:\n        return [tok.text for tok in my_tok.tokenizer(sub_br(x))]\n    except:\n        return []\n#         #isnan\n#         return []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w1 = list(train['question1'].apply(lambda x: set(x.split())))\nw2 = list(train['question2'].apply(lambda x: set(x.split())))\nw3 = list(test['question1'].apply(lambda x: set(x.split())))\nw4 = list(test['question2'].apply(lambda x: set(x.split())))\ntotal_words = set.intersection(*w1)|set.intersection(*w2)|set.intersection(*w3)|set.intersection(*w4)\n\ntotal_words=set.intersection(*total_words)\nprint(total_words)\nnum_words = len(total_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(total_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t = Tokenizer()\nt.fit_on_texts(total_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t.word_counts","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-14T00:40:20.063283Z","start_time":"2019-06-14T00:38:32.149341Z"},"trusted":true},"cell_type":"code","source":"train['question1']=train['question1'].apply(spacy_tok)\ntrain['question2']=train['question2'].apply(spacy_tok)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['question1']=test['question1'].apply(spacy_tok)\ntest['question2']=test['question2'].apply(spacy_tok)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make Counter"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-14T00:41:28.760160Z","start_time":"2019-06-14T00:41:27.327620Z"},"trusted":true},"cell_type":"code","source":"counts = Counter()\nfor question_words in train['question1']:\n    counts.update(question_words)\nfor question_words in train['question2']:\n    counts.update(question_words)\nfor question_words in test['question1']:\n    counts.update(question_words)\nfor question_words in test['question2']:\n    counts.update(question_words)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-14T00:41:41.721107Z","start_time":"2019-06-14T00:41:41.716536Z"},"trusted":true},"cell_type":"code","source":"len(counts)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Delete rare words"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-14T00:41:43.006492Z","start_time":"2019-06-14T00:41:42.915678Z"},"trusted":true},"cell_type":"code","source":"for word in list(counts):\n    if counts[word] < 3:\n        del counts[word]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = keras.preprocessing.text.one_hot(text, n=len(counts), filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-14T00:41:44.280357Z","start_time":"2019-06-14T00:41:44.264535Z"},"trusted":true},"cell_type":"code","source":"vocab2index = {\"\":0, \"UNK\":1}\nwords = [\"\", \"UNK\"]\nfor word in counts:\n    vocab2index[word] = len(words)\n    words.append(word)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-14T00:41:44.699597Z","start_time":"2019-06-14T00:41:44.692407Z"},"trusted":true},"cell_type":"code","source":"\n\n# note that spacy_tok takes a while run it just once\ndef encode_sentence(word_list, vocab2index=vocab2index, N=embedding_size, padding_start=False):\n    x = word_list\n    enc = np.zeros(N, dtype=np.int32)\n    enc1 = np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in x])\n    l = min(N, len(enc1))\n    if padding_start:\n        enc[:l] = enc1[:l]\n    else:\n        enc[N-l:] = enc1[:l]\n    return enc, l\n\n","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-14T00:41:47.959430Z","start_time":"2019-06-14T00:41:44.966160Z"},"trusted":true},"cell_type":"code","source":"train['question1']=train['question1'].apply(encode_sentence)\ntrain['question2']=train['question2'].apply(encode_sentence)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-14T00:41:49.509785Z","start_time":"2019-06-14T00:41:47.961318Z"},"trusted":true},"cell_type":"code","source":"val['question1']=val['question1'].apply(encode_sentence)\nval['question2']=val['question2'].apply(encode_sentence)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"number of words for embeddings"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-14T00:41:49.517812Z","start_time":"2019-06-14T00:41:49.511997Z"},"trusted":true},"cell_type":"code","source":"num_words=len(words)\nnum_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"val.head()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-14T00:41:50.970107Z","start_time":"2019-06-14T00:41:50.962516Z"},"trusted":true},"cell_type":"code","source":"class Question_Dataset(Dataset):\n    def __init__(self,df,train):\n    \n        self.y = torch.Tensor(df['is_duplicate'].values)\n        self.x1 = df['question1']\n        self.x2 = df['question2']\n        \n        \n    def __getitem__(self,idx):\n        x1, s1 = self.x1.loc[idx]\n        x2, s2 = self.x2.loc[idx]\n        x1=torch.Tensor(x1)\n        x2=torch.Tensor(x2)\n        return({\"x1\":x1,'x2':x2,\"s1\":s1,'s2':s2,'y':self.y[idx]})\n    def __len__(self):\n        return len(self.y)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-14T00:41:51.354568Z","start_time":"2019-06-14T00:41:51.335238Z"},"trusted":true},"cell_type":"code","source":"train.reset_index(inplace=True)\nval.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-14T00:41:51.692637Z","start_time":"2019-06-14T00:41:51.646800Z"},"trusted":true},"cell_type":"code","source":"train_ds = Question_Dataset(train,train=True)\nval_ds = Question_Dataset(val,train=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"ExecuteTime":{"end_time":"2019-06-14T00:41:52.311344Z","start_time":"2019-06-14T00:41:52.294616Z"},"trusted":true},"cell_type":"code","source":"class Questionnaire(nn.Module):\n    def __init__(self):\n        super(Questionnaire,self).__init__()\n        self.lstm = nn.LSTM(embedding_size, hidden_dim, batch_first=True).cuda()\n        self.embedding =nn.Embedding(num_words,embedding_size, padding_idx=0)\n        self.dropout = nn.Dropout(0.5)\n    def forward(self,x,s):\n        s, sort_index = torch.sort(s, 0,descending=True)\n        s = s.long().cpu().numpy().tolist()\n        x=self.embedding(x)\n        x=self.dropout(x)\n        x_pack = pack_padded_sequence(x.float(), list(s), batch_first=True)\n        out_pack, (ht, ct) = self.lstm(x_pack)\n        out=ht[-1]\n        return torch.zeros_like(out).scatter_(0, sort_index.unsqueeze(1).expand(-1,out.shape[1]), out)\n         ","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-14T00:45:25.398188Z","start_time":"2019-06-14T00:45:25.384443Z"},"trusted":true},"cell_type":"code","source":"def val_metrics(model, valid_dl,eval_metric=F.nll_loss):\n    model.eval()\n    total = 0\n    sum_loss = 0\n    sum_loss2=0\n    correct = 0 \n    rand_int = np.random.randint(len(valid_dl),size=1)\n    \n    for i, input in enumerate(valid_dl):\n        if i in rand_int:\n            x1 = input['x1'].cuda().long()\n            x2 = input['x2'].cuda().long()\n            s1 = input['s1'].cuda().long()\n            y = input['y'].cuda().float()\n\n            s2 = input['s2'].cuda().long()\n            y_hat_1 = model(x1,s1)\n            y_hat_2 = model(x2,s2)\n            DISTANCE = torch.exp(-torch.abs(y_hat_2-y_hat_1).sum(-1))\n#             DISTANCE = DISTANCE.unsqueeze(1)\n#             DISTANCE = torch.cat([1-DISTANCE,DISTANCE],1).float()\n            xt1 = [words[int(x)] for x in x1[0]]\n            xt2 = [words[int(x)] for x in x2[0]]\n            loss = F.mse_loss(DISTANCE,y)\n\n            print('Sentence 1: ',' '.join(xt1))\n            print('Sentence 2:',' '.join(xt2))\n            print('Prediction:',str(float(DISTANCE[0])))\n            print('Actual:',str(float(y[0])))\n        x1 = input['x1'].cuda().long()\n        x2 = input['x2'].cuda().long()\n        s1 = input['s1'].cuda().long()\n        s2 = input['s2'].cuda().long()\n        y_hat_1 = model(x1,s1)\n        y_hat_2 = model(x2,s2)\n\n        DISTANCE = torch.exp(-torch.abs(y_hat_2-y_hat_1).sum(-1))\n        DISTANCE = DISTANCE.unsqueeze(1)\n        DISTANCE = torch.cat([1-DISTANCE,DISTANCE],1).float()\n\n        y = input['y'].cuda().long()\n\n        loss = eval_metric(DISTANCE,y)\n        batch=y.shape[0]\n\n        sum_loss += batch*(loss.item())\n        total += batch\n    print(\"Validation Log Loss: \", sum_loss/total)\n    return sum_loss/total","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-14T00:45:26.081196Z","start_time":"2019-06-14T00:45:26.070452Z"},"trusted":true},"cell_type":"code","source":"def train_routine(model,train_ds,valid_ds,epochs,eval_metric=F.mse_loss):\n    model.train()\n    optimizer = torch.optim.Adam(model.parameters(),learning_rate)\n    train_dl = DataLoader(train_ds,batch_size,True)\n    val_dl = DataLoader(val_ds,batch_size,True)\n    valid_errors = []\n    train_errors = []\n    for epoch in range(epochs):\n        model.train()\n\n        sum_loss=0\n        total=0\n        for i, input in enumerate(train_dl):\n            optimizer.zero_grad()\n            x1 = input['x1'].cuda().long()\n            x2 = input['x2'].cuda().long()\n            s1 = input['s1'].cuda().long()\n            s2 = input['s2'].cuda().long()\n\n            y_hat_1 = model(x1,s1)\n            y_hat_2 = model(x2,s2)\n            DISTANCE = torch.exp(-torch.abs(y_hat_2-y_hat_1).sum(-1))\n#             DISTANCE = DISTANCE.unsqueeze(1)\n#             DISTANCE = torch.cat([1-DISTANCE,DISTANCE],1).float()\n            \n            y = input['y'].float().cuda()\n            \n            loss = eval_metric(DISTANCE,y)\n            loss.backward()\n            total+=y.shape[0]\n            sum_loss+=loss.item()\n            optimizer.step()\n        print(\"Training Mean Squared error: \", sum_loss/total)\n        train_errors.append(sum_loss/total)\n        valid_errors.append(val_metrics(model,val_dl))\n        print()\n    return train_errors, valid_errors","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-14T00:45:26.782951Z","start_time":"2019-06-14T00:45:26.678369Z"},"trusted":true},"cell_type":"code","source":"model = Questionnaire().cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=model.cuda()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2019-06-14T00:50:34.435777Z","start_time":"2019-06-14T00:45:27.298956Z"},"trusted":true},"cell_type":"code","source":"learning_rate=0.0001\n\ntrain_errors, val_errors = train_routine(model,train_ds,val_ds,epochs,eval_metric=F.mse_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_errors)\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(val_errors)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate=0.001\nnewtrain_errors, newval_errors = train_routine(model,train_ds,val_ds,epochs,eval_metric=F.mse_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs=5\nlearning_rate=0.0001\nnewesttrain_errors, newestval_errors = train_routine(model,train_ds,val_ds,epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_errors+newtrain_errors+newesttrain_errors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(val_errors+newval_errors+newestval_errors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['question1']=test['question1'].apply(spacy_tok)\ntest['question2']=test['question2'].apply(spacy_tok)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testcounts = Counter()\nfor question_words in test['question1']:\n    testcounts.update(question_words)\nfor question_words in test['question2']:\n    testcounts.update(question_words)\nfor word in list(counts):\n    if testcounts[word] < 3:\n        del testcounts[word]\nvocab2index = {\"\":0, \"UNK\":1}\nwords = [\"\", \"UNK\"]\nfor word in testcounts:\n    vocab2index[word] = len(words)\n    words.append(word)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['question1']=test['question1'].apply(encode_sentence)\ntest['question2']=test['question2'].apply(encode_sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\npredictions = []\nfor row in range(len(test)):\n    print(row)\n    x1, s1 = test['question1'].loc[row]\n    x2, s2 = test['question2'].loc[row]\n    x2=torch.Tensor(x1).long().cuda()\n    s1=torch.Tensor(s1)\n    x1=torch.Tensor(x1).long().cuda()\n    s2=torch.Tensor(s2)\n    curr = 50-s1.shape[0]\n    attach = torch.zeros(curr)\n    s1=torch.cat([attach,s1])\n    curr = 50-s2.shape[0]\n    attach = torch.zeros(curr)\n    s2=torch.cat([attach,s2])\n    print(s1)\n    y_hat_1 = model(x1,s1)\n    y_hat_2 = model(x2,s2)\n    prediction = torch.exp(-torch.abs(y_hat_2-y_hat_1).sum(-1))\n    predictions.append(prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_submission = pd.DataFrame({'test_id': np.array( range(len(predictions))), 'is_duplicate':np.array( predictions)})\nmy_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import the modules we'll need\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"submission.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n# create a random sample dataframe\ndf = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))\n\n# create a link to download the dataframe\ncreate_download_link(df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}