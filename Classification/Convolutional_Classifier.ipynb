{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2282e0e6-bed3-4375-5b9b-05c80fe29f27"
   },
   "source": [
    "This notebook uses a pretrained model (inception v3) to classify plants as invasive or not.\n",
    "---------------------------\n",
    "I ended up getting to 92% accuracy after 10 epochs. I only trained the pretrained weights at a low learning rates every fifth epoch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for the file structure is I ran this on a kaggle kernal initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T23:05:47.569057Z",
     "start_time": "2019-06-12T23:05:46.483953Z"
    },
    "_cell_guid": "aab06a15-51b8-13e2-172a-b3e62aa3738a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import math\n",
    "from glob import glob\n",
    "import os\n",
    "from sklearn import metrics\n",
    "import glob2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fdca4192-cf9d-1f5f-7e8f-30ae5e468db4"
   },
   "source": [
    "## resize train data and test data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "e68a78fc-8470-e081-27ad-eca99e6fdd1f"
   },
   "outputs": [],
   "source": [
    "img_path = \"../input/train/\"\n",
    "\n",
    "y = []\n",
    "file_paths = []\n",
    "for i in range(len(master)-750):\n",
    "    file_paths.append( img_path + str(master.loc[i][0]) +'.jpg' )\n",
    "    y.append(master.loc[i][1])\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "34636940-b7b8-64f6-6ca7-1ad97081ea7b"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "PATH = Path(\".\")\n",
    "\n",
    "def get_optimizer(model, lr = 0.01, wd = 0.0):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim\n",
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))\n",
    "def get_triangular_lr(lr_low, lr_high, stepesize):\n",
    "    iterations = 2*stepesize\n",
    "    iter1 = int(0.35*iterations)\n",
    "    iter2 = int(0.85*iter1)\n",
    "    iter3 = iterations - iter1 - iter2\n",
    "    delta1 = (lr_high - lr_low)/iter1\n",
    "    delta2 = (lr_high - lr_low)/(iter1 -1)\n",
    "    lrs1 = [lr_low + i*delta1 for i in range(iter1)]\n",
    "    lrs2 = [lr_high - i*(delta1) for i in range(0, iter2)]\n",
    "    delta2 = (lrs2[-1] - lr_low)/(iter3)\n",
    "    lrs3 = [lrs2[-1] - i*(delta2) for i in range(1, iter3+1)]\n",
    "    return lrs1+lrs2+lrs3\n",
    "def train_triangular_policy(model, train_dl, valid_dl, lr_low=1e-5, lr_high=0.01):\n",
    "    idx = 0\n",
    "    epochs = 1\n",
    "    stepesize = 2*len(train_dl)\n",
    "    lrs = get_triangular_lr(lr_low, lr_high, stepesize)\n",
    "\n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    for i, (mod_input) in enumerate(train_dl):\n",
    "        x,y = mod_input['x'],mod_input['y']\n",
    "\n",
    "        optim = get_optimizer(model, lr = lrs[idx], wd =0)\n",
    "        batch = y.shape[0]\n",
    "        x = x.cuda().float()\n",
    "        y = y.cuda().float().unsqueeze(1)\n",
    "        out = model(x)[0]\n",
    "        loss =  F.binary_cross_entropy_with_logits(out, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        idx += 1\n",
    "        total += batch\n",
    "        sum_loss += batch*(loss.item())\n",
    "    print(\"train loss\", sum_loss/total)\n",
    "    train_loss=sum_loss/total\n",
    "\n",
    "        \n",
    "\n",
    "def training_loop(model, train_dl, valid_dl, steps=3, lr_low=1e-5, lr_high=0.01):\n",
    "\n",
    "    start = datetime.now() \n",
    "    train_loss = train_triangular_policy(model, train_dl, valid_dl, lr_low, lr_high)\n",
    "    end = datetime.now()\n",
    "    t = 'Time elapsed {}'.format(end - start)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image reseize & centering & crop \n",
    "\n",
    "import math\n",
    "def center_crop(im, min_sz=299):\n",
    "    \"\"\" Returns a center crop of an image\"\"\"\n",
    "    \"\"\" Returns a random crop\"\"\"\n",
    "    r,c,*_ = im.shape\n",
    "    start_c = 0\n",
    "    print(im.shape)\n",
    "    if im.shape[2]< im.shape[1]:\n",
    "\n",
    "        return crop(im, 0, start_c, min_sz, min_sz)\n",
    "    else:\n",
    "\n",
    "        \n",
    "        return crop(im,start_c, 0, min_sz, min_sz)\n",
    "\n",
    "def crop(im, r, c, target_r, target_c): return im[:,r:r+target_r, c:c+target_c]\n",
    "\n",
    "def random_crop(x,target_size = 2):\n",
    "    \"\"\" Returns a random crop\"\"\"\n",
    "    r,c,*_ = x.shape\n",
    "    rand_c = np.random.uniform(0, 1)*32\n",
    "    start_c = np.floor(rand_c).astype(int)\n",
    "    \n",
    "    if x.shape[2]< x.shape[1]:\n",
    "        return crop(x, 0, start_c, target_size, target_size)\n",
    "    else:\n",
    "        return crop(x,start_c, 0, target_size, target_size)\n",
    "\n",
    "def rotate_cv(im,  mode=cv2.BORDER_REFLECT, interpolation=cv2.INTER_AREA):\n",
    "    \"\"\" Rotates an image by deg degrees\"\"\"\n",
    "    r,c,*_ = im.shape\n",
    "    deg = np.random.rand() * 180\n",
    "    M = cv2.getRotationMatrix2D((c/2,r/2),deg,1)\n",
    "\n",
    "    return cv2.warpAffine(im,M,(c,r), borderMode=mode, flags=cv2.WARP_FILL_OUTLIERS+interpolation)\n",
    "\n",
    "def random_flip(x):\n",
    "    p = np.random.rand()\n",
    "    if p>0.5:\n",
    "        return np.flip(x,1).copy()\n",
    "    else:\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9d5db4fe-b1ca-80d9-eb5a-decb9e71fa8b"
   },
   "source": [
    "save numpy array.\n",
    "\n",
    "Usually I separate code, data format and CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2880329f-76a5-b385-a3ba-609820535f34"
   },
   "source": [
    "## split train data and validation data  ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerDataset(Dataset):\n",
    "    def __init__(self,img_paths,y,transform=False):\n",
    "        self.X=img_paths\n",
    "        self.y=y\n",
    "        if transform: self.transform = lambda x: random_flip(rotate_cv(x))\n",
    "        else: self.transform = lambda x: x\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img = cv2.imread(self.X[idx])\n",
    "        img = img.astype('float64')\n",
    "\n",
    "        img[:,:,0] -= 103.939\n",
    "        img[:,:,1] -= 116.779\n",
    "        img[:,:,2] -= 123.68\n",
    "        img /= 255.\n",
    "        #resize \n",
    "        img = cv2.resize(img,(299,299)).T \n",
    "        return {'x':self.transform(img),'y':self.y[idx]}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "class TestFlowerDataset(Dataset):\n",
    "    def __init__(self,img_paths,transform=False):\n",
    "        self.X=img_paths\n",
    "        self.y=y\n",
    "        if transform: self.transform = lambda x: random_flip(rotate_cv(x))\n",
    "        else: self.transform = lambda x: x\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img = cv2.imread(self.X[idx])\n",
    "        img = img.astype('float64')\n",
    "\n",
    "        img[:,:,0] -= 103.939\n",
    "        img[:,:,1] -= 116.779\n",
    "        img[:,:,2] -= 123.68\n",
    "        img /= 255.\n",
    "        #resize \n",
    "        img = cv2.resize(img,(299,299)).T \n",
    "        return {'x':self.transform(img),'y':self.y}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T01:40:52.503691Z",
     "start_time": "2019-06-03T01:40:52.477289Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def val_metrics(model, valid_dl):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0 \n",
    "    for input in valid_dl:\n",
    "        model.eval()\n",
    "\n",
    "        x = input['x'].cuda()\n",
    "        y = input['y'].long().cuda()\n",
    "        batch = y.shape[0]\n",
    "        x = x.cuda().float()\n",
    "        y = y.cuda().unsqueeze(1)\n",
    "        out = model(x)\n",
    "        pred = (out > 0.0).long()\n",
    "        correct += pred.eq(y.data).sum().item()\n",
    "        y = y.float()\n",
    "        loss = F.binary_cross_entropy_with_logits(out, y)\n",
    "        sum_loss += batch*(loss.item())\n",
    "        total += batch\n",
    "    print(\"val loss and accuracy\", sum_loss/total, correct/total)\n",
    "    return correct/total\n",
    "\n",
    "\n",
    "def eval(model, valid_dl):\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    probs = []\n",
    "    ys= []\n",
    "    for input in valid_dl:\n",
    "        model.eval()\n",
    "\n",
    "        x = input['x'].cuda()\n",
    "        y = input['y'].float().cuda()\n",
    "        batch = y.shape[0]\n",
    "        \n",
    "        y_hat = model(x.float()).flatten() \n",
    "    \n",
    "        \n",
    "        probs.append(int(y_hat[0].cpu().detach().numpy()>0.5))\n",
    "\n",
    "        ys.append(int(y.cpu().detach().numpy()[0]))\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat,y).cuda()\n",
    "        sum_loss += batch * loss.item()\n",
    "        total+=batch\n",
    "\n",
    "    probs = np.vstack(probs)\n",
    "    ys = np.vstack(ys)\n",
    "    \n",
    "    acc = metrics.accuracy_score(ys, probs)\n",
    "    torch.cuda.empty_cache()\n",
    "    return sum_loss/total, acc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:47:13.595523Z",
     "start_time": "2019-06-03T02:47:13.123970Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-038360c25223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)\n",
    "        \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        inception = models.inception_v3(pretrained='imagenet',transform_input=True) \n",
    "        # freezing parameters\n",
    "        for i, param in inception.named_parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "\n",
    "        in_filters = inception.fc.in_features\n",
    "        \n",
    "        # convolutional layers of resnet34\n",
    "\n",
    "        \n",
    "        last_layer = nn.Sequential(*[\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(in_filters),    \n",
    "            nn.Linear(in_filters, in_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(in_filters),\n",
    "            nn.Linear(in_filters, 1)])\n",
    "        inception.fc = last_layer\n",
    "        self.inception = inception\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.inception(x)\n",
    "        print(type(x))\n",
    "        return torch.Tensor(x)\n",
    "    def freeze(self):\n",
    "        for i, param in self.inception.named_parameters():\n",
    "            param.requires_grad = False\n",
    "    def unfreeze(self):\n",
    "        for i, param in self.inception.named_parameters():\n",
    "            param.requires_grad = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:47:13.596266Z",
     "start_time": "2019-06-03T02:47:13.469Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Net().cuda()\n",
    "epochs = 1000\n",
    "learning_rate = 0.001\n",
    "weight_decay=0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor=0.25, patience=1,cooldown=1, min_lr=1e-7,verbose=True)\n",
    "train_input,val_input,train_output,val_output = train_test_split(file_paths,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:47:14.283104Z",
     "start_time": "2019-06-03T02:47:14.274370Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FlowerDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-269e9dda012b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mFlowerDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mFlowerDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FlowerDataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset= FlowerDataset(train_input,train_output,transform=True)\n",
    "val_dataset= FlowerDataset(val_input,val_output,transform=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_size=12,shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset,batch_size=12,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.5278502881835779\n",
      "val loss and accuracy 0.4389747302084006 0.9121447028423773\n",
      "train loss 0.6760029819036395\n",
      "val loss and accuracy 2.1288044434185176 0.648578811369509\n",
      "train loss 0.4882872643557237\n",
      "val loss and accuracy 1.8981971070747967 0.8191214470284238\n",
      "train loss 0.40129411205108917\n",
      "val loss and accuracy 0.4540959900432779 0.7984496124031008\n",
      "train loss 0.39882178882551933\n",
      "val loss and accuracy 19.723487713540248 0.4160206718346253\n",
      "train loss 0.32844588901712485\n",
      "val loss and accuracy 0.31558458160522374 0.8682170542635659\n",
      "train loss 0.40021285738969714\n",
      "val loss and accuracy 0.42350348576094754 0.8552971576227391\n",
      "train loss 0.39202842791926673\n",
      "val loss and accuracy 0.700088641902273 0.6330749354005168\n",
      "train loss 0.4348357002506602\n",
      "val loss and accuracy 0.3407989811989688 0.8578811369509044\n",
      "train loss 0.3771199317639356\n",
      "val loss and accuracy 66.05415870607361 0.3695090439276486\n",
      "train loss 0.3220565038023835\n",
      "val loss and accuracy 0.2690491846134496 0.8811369509043928\n",
      "train loss 0.35463675455108207\n",
      "val loss and accuracy 0.27734229638594987 0.8940568475452196\n",
      "train loss 0.33835657898317345\n",
      "val loss and accuracy 0.31418720419092694 0.8656330749354005\n",
      "train loss 0.33329510206231183\n",
      "val loss and accuracy 63.240737019583236 0.7131782945736435\n",
      "train loss 0.33536988770869114\n",
      "val loss and accuracy 0.2874552667603012 0.9250645994832042\n"
     ]
    }
   ],
   "source": [
    "train_losses=[]\n",
    "val_losses=[]\n",
    "last_acc=0\n",
    "val_accs=[]\n",
    "lr_low=0.0005\n",
    "lr_high=0.002\n",
    "for epoch in range(15):\n",
    "    avg_val_acc = 0\n",
    "    avg_train_loss = 0 \n",
    "    avg_val_loss = 0\n",
    "       \n",
    "    total_loss=0\n",
    "    total=0\n",
    "    if epoch%5 == 0:\n",
    "        model.unfreeze()\n",
    "        train_loss = training_loop(model, train_dataloader, val_dataloader, steps=1, lr_low=1e-5,lr_high=0.0005 )\n",
    "        model.freeze()\n",
    "    else:\n",
    "        model.unfreeze()\n",
    "        train_loss = training_loop(model, train_dataloader, val_dataloader, steps=1, lr_low=lr_low,lr_high=lr_high)\n",
    "        model.freeze()\n",
    "    val_acc = val_metrics(model, val_dataloader)\n",
    "    val_losses.append(val_acc)\n",
    "\n",
    "#     if val_acc < last_acc:\n",
    "#         lr_low*=0.8\n",
    "#         lr_high*=0.8\n",
    "#         print('Shrinking Learning Rate to:',str(lr_low),'to,',str(lr_high))\n",
    "    last_acc = val_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(paths):\n",
    "    imf_d = {}\n",
    "    for f in paths:\n",
    "        imf_d[f] = f\n",
    "    fdata = [imf_d[f] for f in paths]\n",
    "    return fdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,f='new_mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_jpg = glob('../input/test/*.jpg')\n",
    "test = pd.DataFrame([[p.split('/')[3].replace('.jpg',''),p] for p in test_jpg])\n",
    "test.columns = ['name','path']\n",
    "xtest = load_img(test['path']); print('test...')\n",
    "pd.DataFrame.from_dict(xtest).to_csv('xtest1.csv', index=False)\n",
    "xtest = pd.read_csv('xtest1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_p = '../input/test/'\n",
    "\n",
    "\n",
    "file_paths = []\n",
    "for i in range(len(xtest)):\n",
    "    file_paths.append( str(xtest.loc[i][0]) )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [0 for x in range(len(file_paths))]\n",
    "name = lambda x:int( x.split('/')[-1].split('.')[0])\n",
    "for x in file_paths:\n",
    "    print(name(x))\n",
    "    model.eval()\n",
    "    img = cv2.imread(x)\n",
    "    img = img.astype('float64')\n",
    "\n",
    "    img[:,:,0] -= 103.939\n",
    "    img[:,:,1] -= 116.779\n",
    "    img[:,:,2] -= 123.68\n",
    "    img /= 255.\n",
    "    #resize \n",
    "    img = np.rollaxis(cv2.resize(img,(299,299)),2)\n",
    "    img=torch.Tensor(random_flip(rotate_cv(img))).unsqueeze(0).cuda()\n",
    "    predictions[name(x)] = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[int(pred) for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'new.csv'\n",
    "with open(filename,'w+') as f:\n",
    "    f.write(\"name,invasive\\n\")\n",
    "    for i, prediction in enumerate([int(pred) for pred in predictions]):\n",
    "        line = str(i)+','+str(prediction)+'\\n'\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My personal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(*[nn.Conv2d(3,10,kernel_size=2,stride=2),\\\n",
    "                       nn.ReLU(True),\\\n",
    "                       nn.BatchNorm2d(10),#128\n",
    "                        nn.Conv2d(10,9,kernel_size=2,stride=2),\\\n",
    "                       nn.ReLU(True),\\\n",
    "                       nn.BatchNorm2d(9),#64\n",
    "                        nn.Conv2d(9,8,kernel_size=2,stride=2),\\\n",
    "                       nn.ReLU(True),\\\n",
    "                       nn.BatchNorm2d(8),   #32\n",
    "                        nn.Conv2d(8,7,kernel_size=2,stride=2),\\\n",
    "                       nn.ReLU(True),\\\n",
    "                       nn.BatchNorm2d(7),  #16\n",
    "                        nn.Conv2d(7,6,kernel_size=2,stride=2),\\\n",
    "                       nn.ReLU(True),\\\n",
    "                       nn.BatchNorm2d(6),  #8\n",
    "                        nn.Conv2d(6,5,kernel_size=2,stride=2),\\\n",
    "                       nn.ReLU(True),\\\n",
    "                       nn.BatchNorm2d(5),  #4\n",
    "                        nn.Conv2d(5,1,kernel_size=2,stride=2)\n",
    "                       ]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "weight_decay=0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate,weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "\n",
    "# function that takes in a dataframe and creates a text link to  \n",
    "# download it (will only work for files < 2MB or so)\n",
    "def create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n",
    "    csv = df.to_csv()\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "# create a random sample dataframe\n",
    "df = pd.read_csv('new.csv')\n",
    "\n",
    "# create a link to download the dataframe\n",
    "create_download_link(df)"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
